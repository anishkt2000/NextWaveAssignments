{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9edb74c",
   "metadata": {},
   "source": [
    "import important library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e97beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e90043",
   "metadata": {},
   "source": [
    "Function For loading and pre_processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396e3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    # Load the data\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use .csv or .xlsx\")\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Handle missing data\n",
    "    df = df.dropna()  # Remove rows with missing data\n",
    "    \n",
    "    # Convert amount to float\n",
    "    df['amount'] = df['amount'].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f31a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(df):\n",
    "    stats = df.groupby('category')['amount'].agg(['mean', 'median', 'std'])\n",
    "    print(df)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c10e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_thresholds(stats, z_score=3):\n",
    "    thresholds = stats.copy()\n",
    "    thresholds['upper_threshold'] = thresholds['mean'] + z_score * thresholds['std']\n",
    "    thresholds['lower_threshold'] = thresholds['mean'] - z_score * thresholds['std']\n",
    "    return thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1d0efd",
   "metadata": {},
   "source": [
    "The function detect_amount_anomalies identifies outliers in transaction amounts per category using z-scores. It iterates through each category, calculates mean and standard deviation excluding each transaction iteratively, computes z-scores, flags anomalies exceeding a threshold, and returns a DataFrame listing anomaly details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d725545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_amount_anomalies(df, z_score_threshold=3):\n",
    "    anomalies = []\n",
    "    \n",
    "    for category in df['category'].unique():\n",
    "        category_df = df[df['category'] == category]\n",
    "        \n",
    "        for idx, row in category_df.iterrows():\n",
    "            # Exclude the current transaction\n",
    "            other_transactions = category_df.drop(idx)\n",
    "            \n",
    "            # Calculate mean and std without the current transaction\n",
    "            mean = other_transactions['amount'].mean()\n",
    "            std = other_transactions['amount'].std()\n",
    "            \n",
    "            # Calculate z-score for the current transaction\n",
    "            z_score = (row['amount'] - mean) / std if std != 0 else 0\n",
    "            \n",
    "            if abs(z_score) > z_score_threshold:\n",
    "                anomalies.append({\n",
    "                    'transaction_id': row['transaction_id'],\n",
    "                    'date': row['date'],\n",
    "                    'category': category,\n",
    "                    'amount': row['amount'],\n",
    "                    'reason_for_anomaly': f\"Amount anomaly (z-score: {z_score:.2f})\"\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a28ea",
   "metadata": {},
   "source": [
    "The function detect_frequency_anomalies identifies sudden increases in transaction frequency per category within a DataFrame df. It sorts the DataFrame by date, calculates transaction counts over a rolling window, computes average counts, and flags anomalies where counts exceed a threshold relative to the average. Anomalies are logged with transaction details and returned as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe713ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_frequency_anomalies(df, window=3, threshold_multiplier=2):\n",
    "    df_sorted = df.sort_values('date')\n",
    "    frequency_anomalies = []\n",
    "    \n",
    "    for category in df['category'].unique():\n",
    "        category_df = df_sorted[df_sorted['category'] == category].copy()\n",
    "        category_df.loc[:, 'transaction_count'] = category_df['date'].rolling(window, min_periods=0).count()\n",
    "        category_df.loc[:, 'avg_transaction_count'] = category_df['transaction_count'].rolling(window * 2, min_periods=0).mean().shift(1)\n",
    "        \n",
    "        for _, row in category_df.iterrows():\n",
    "            if row['transaction_count'] > threshold_multiplier * row['avg_transaction_count']:\n",
    "                frequency_anomalies.append({\n",
    "                    'transaction_id': row['transaction_id'],\n",
    "                    'date': row['date'],\n",
    "                    'category': category,\n",
    "                    'amount': row['amount'],\n",
    "                    'reason_for_anomaly': f\"Sudden frequency increase (count: {row['transaction_count']}, avg: {row['avg_transaction_count']:.2f})\"\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(frequency_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966317d3",
   "metadata": {},
   "source": [
    "The function detect_pattern_anomalies identifies irregular patterns in transaction amounts per category within a DataFrame df. It sorts the DataFrame by date and computes a moving average and standard deviation of transaction amounts over a specified window. Anomalies are detected when the absolute deviation from the moving average exceeds twice the standard deviation. Anomalies are logged with transaction details and returned as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa15311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pattern_anomalies(df, window=7):\n",
    "    pattern_anomalies = []\n",
    "    df_sorted = df.sort_values('date')\n",
    "    \n",
    "    for category in df['category'].unique():\n",
    "        category_df = df_sorted[df_sorted['category'] == category].copy()\n",
    "        category_df.loc[:, 'amount_moving_avg'] = category_df['amount'].rolling(window=window, min_periods=0).mean()\n",
    "        category_df.loc[:, 'amount_std'] = category_df['amount'].rolling(window=window, min_periods=0).std()\n",
    "        \n",
    "        for _, row in category_df.iterrows():\n",
    "            if abs(row['amount'] - row['amount_moving_avg']) > 2 * row['amount_std']:\n",
    "                pattern_anomalies.append({\n",
    "                    'transaction_id': row['transaction_id'],\n",
    "                    'date': row['date'],\n",
    "                    'category': category,\n",
    "                    'amount': row['amount'],\n",
    "                    'reason_for_anomaly': f\"Irregular pattern (amount: {row['amount']:.2f}, moving avg: {row['amount_moving_avg']:.2f}, std: {row['amount_std']:.2f})\"\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(pattern_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce35c96a",
   "metadata": {},
   "source": [
    "function for detailed report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1d47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(anomalies):\n",
    "    print(\"Anomaly Detection Report\")\n",
    "    print(\"========================\")\n",
    "    print(f\"Total anomalies detected: {len(anomalies)}\")\n",
    "    \n",
    "    print(\"\\nAnomalies by Type:\")\n",
    "    print(anomalies['reason_for_anomaly'].value_counts().to_string())\n",
    "    \n",
    "    print(\"\\nAnomalies by Category:\")\n",
    "    print(anomalies['category'].value_counts().to_string())\n",
    "    \n",
    "    print(\"\\nDetailed Anomalies:\")\n",
    "    print(anomalies.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a5430d",
   "metadata": {},
   "source": [
    "main function is to execute the above function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a6ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path):\n",
    "    # 1. Data Preprocessing\n",
    "    df = load_and_preprocess_data(file_path)\n",
    "    \n",
    "    # 2. Anomaly Detection\n",
    "    amount_anomalies = detect_amount_anomalies(df)  # Using default z_score_threshold of 3\n",
    "    frequency_anomalies = detect_frequency_anomalies(df)\n",
    "    pattern_anomalies = detect_pattern_anomalies(df)\n",
    "    \n",
    "    # Combine all anomalies\n",
    "    all_anomalies = pd.concat([amount_anomalies, frequency_anomalies, pattern_anomalies], ignore_index=True)\n",
    "    \n",
    "    if all_anomalies.empty:\n",
    "        print(\"No anomalies detected.\")\n",
    "    else:\n",
    "        # Sort anomalies by date if the date column exists\n",
    "        if 'date' in all_anomalies.columns:\n",
    "            all_anomalies = all_anomalies.sort_values('date')\n",
    "        \n",
    "        # 3. Reporting\n",
    "        generate_report(all_anomalies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d236c4",
   "metadata": {},
   "source": [
    "# store dataset path in file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aeddc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =\"transaction.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744935a0",
   "metadata": {},
   "source": [
    "execute with the above path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63fe3ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Detection Report\n",
      "========================\n",
      "Total anomalies detected: 1\n",
      "\n",
      "Anomalies by Type:\n",
      "Amount anomaly (z-score: 842.16)    1\n",
      "\n",
      "Anomalies by Category:\n",
      "Food    1\n",
      "\n",
      "Detailed Anomalies:\n",
      "transaction_id       date category  amount               reason_for_anomaly\n",
      "        TRX004 2024-06-02     Food  3000.0 Amount anomaly (z-score: 842.16)\n"
     ]
    }
   ],
   "source": [
    "main(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d86cab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
